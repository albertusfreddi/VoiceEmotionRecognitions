{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import soundfile\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotions to observe and list of file\n",
    "observedEmotions=['neutral', 'happy', 'angry']\n",
    "neutral = []\n",
    "happy = []\n",
    "angry = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotions in the RAVDESS dataset\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "\n",
    "# Sum data set and split\n",
    "for file in glob.glob(\"D:\\\\belajar IT\\Purwadhika JC Data Science\\Code\\\\Final Project\\\\ravdess-emotional-speech-audio\\\\Actor_*\\\\*.wav\"):\n",
    "        fileName=os.path.basename(file)\n",
    "        emotion=emotions[fileName.split(\"-\")[2]]\n",
    "        if emotion not in observedEmotions:\n",
    "            continue\n",
    "        if emotion == 'neutral':\n",
    "            neutral += [file]\n",
    "        elif emotion == 'happy':\n",
    "            happy += [file]\n",
    "        elif emotion == 'angry':\n",
    "            angry += [file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotions in the TESS Toronto emotional speech set data\n",
    "\n",
    "# Sum data set and split\n",
    "for file in glob.glob(\"D:\\\\belajar IT\\Purwadhika JC Data Science\\Code\\\\Final Project\\\\TESS Toronto emotional speech set data\\\\*_angry\\\\*.wav\"):\n",
    "        fileName=os.path.basename(file)\n",
    "        angry += [file]\n",
    "        \n",
    "for file in glob.glob(\"D:\\\\belajar IT\\Purwadhika JC Data Science\\Code\\\\Final Project\\\\TESS Toronto emotional speech set data\\\\*_happy\\\\*.wav\"):\n",
    "        fileName=os.path.basename(file)\n",
    "        happy += [file]\n",
    "        \n",
    "for file in glob.glob(\"D:\\\\belajar IT\\Purwadhika JC Data Science\\Code\\\\Final Project\\\\TESS Toronto emotional speech set data\\\\*_neutral\\\\*.wav\"):\n",
    "        fileName=os.path.basename(file)\n",
    "        neutral += [file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotions in the CREMA-D dataset\n",
    "\n",
    "# Sum data set and split\n",
    "for file in glob.glob(\"D:\\\\belajar IT\\Purwadhika JC Data Science\\Code\\\\Final Project\\\\cremad\\\\AudioWAV\\\\*_NEU_*.wav\"):\n",
    "        fileName=os.path.basename(file)\n",
    "        neutral += [file]\n",
    "        \n",
    "for file in glob.glob(\"D:\\\\belajar IT\\Purwadhika JC Data Science\\Code\\\\Final Project\\\\cremad\\\\AudioWAV\\\\*_HAP_*.wav\"):\n",
    "        fileName=os.path.basename(file)\n",
    "        happy += [file]\n",
    "        \n",
    "for file in glob.glob(\"D:\\\\belajar IT\\Purwadhika JC Data Science\\Code\\\\Final Project\\\\cremad\\\\AudioWAV\\\\*_ANG_*.wav\"):\n",
    "        fileName=os.path.basename(file)\n",
    "        angry += [file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotions in the SAVEE dataset\n",
    "\n",
    "# Sum data set and split\n",
    "for file in glob.glob(\"D:\\\\belajar IT\\Purwadhika JC Data Science\\Code\\\\Final Project\\\\surrey-audiovisual-expressed-emotion-savee\\\\ALL\\\\*.wav\"):\n",
    "        fileName=os.path.basename(file)\n",
    "        emotion= fileName.split(\"_\")[1][0]\n",
    "        if emotion=='a':\n",
    "            angry += [file]\n",
    "        elif emotion=='h':\n",
    "            happy += [file]\n",
    "        elif emotion=='n':\n",
    "            neutral += [file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703 1923 1923\n",
      "5549\n"
     ]
    }
   ],
   "source": [
    "# total file to observe\n",
    "print(len(neutral), len(happy), len(angry))\n",
    "\n",
    "# join all file to 1 list for feature extraction\n",
    "allFile = neutral + happy + angry\n",
    "print(len(allFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (mfcc, chroma) from a sound file\n",
    "def extractFeature(file):\n",
    "    data , sr = librosa.load(file)\n",
    "    hasil=np.array([])\n",
    "    mfccs=np.mean(librosa.feature.mfcc(y=data, sr=sr, n_mfcc=40).T, axis=0)\n",
    "    hasil=np.hstack((hasil, mfccs))\n",
    "    stft=np.abs(librosa.stft(data))\n",
    "    chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sr).T,axis=0)\n",
    "    hasil=np.hstack((hasil, chroma))\n",
    "    return hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-697.984192</td>\n",
       "      <td>55.228489</td>\n",
       "      <td>0.323863</td>\n",
       "      <td>12.775377</td>\n",
       "      <td>7.396148</td>\n",
       "      <td>0.866224</td>\n",
       "      <td>-3.550276</td>\n",
       "      <td>-2.828331</td>\n",
       "      <td>-11.305533</td>\n",
       "      <td>-2.524927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782118</td>\n",
       "      <td>0.739672</td>\n",
       "      <td>0.680501</td>\n",
       "      <td>0.683999</td>\n",
       "      <td>0.728767</td>\n",
       "      <td>0.755843</td>\n",
       "      <td>0.7463</td>\n",
       "      <td>0.744283</td>\n",
       "      <td>0.722983</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1         2          3         4         5         6  \\\n",
       "0 -697.984192  55.228489  0.323863  12.775377  7.396148  0.866224 -3.550276   \n",
       "\n",
       "          7          8         9  ...        43        44        45        46  \\\n",
       "0 -2.828331 -11.305533 -2.524927  ...  0.782118  0.739672  0.680501  0.683999   \n",
       "\n",
       "         47        48      49        50        51  emotions  \n",
       "0  0.728767  0.755843  0.7463  0.744283  0.722983   neutral  \n",
       "\n",
       "[1 rows x 53 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data after feature extraction\n",
    "\n",
    "x,y=[],[]\n",
    "# neutral\n",
    "fileTest = neutral[0]\n",
    "emotion='neutral'\n",
    "feature=extractFeature(fileTest)\n",
    "x.append(feature)\n",
    "y.append(emotion)\n",
    "\n",
    "\n",
    "dfCheck = pd.DataFrame(x)\n",
    "dfCheck['emotions'] = y\n",
    "\n",
    "dfCheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe for Hyper Parameter Tuning using GridSearchCV\n",
    "\n",
    "x,y=[],[]\n",
    "for i in range(0,50):\n",
    "    # neutral\n",
    "    fileTest = neutral[i]\n",
    "    emotion='neutral'\n",
    "    feature=extractFeature(fileTest)\n",
    "    x.append(feature)\n",
    "    y.append(emotion)\n",
    "    \n",
    "    # angry\n",
    "    fileTest = angry[i]\n",
    "    emotion='angry'\n",
    "    feature=extractFeature(fileTest)\n",
    "    x.append(feature)\n",
    "    y.append(emotion)\n",
    "    \n",
    "    # happy\n",
    "    fileTest = neutral[i]\n",
    "    emotion='happy'\n",
    "    feature=extractFeature(fileTest)\n",
    "    x.append(feature)\n",
    "    y.append(emotion)\n",
    "\n",
    "\n",
    "dfTest = pd.DataFrame(x)\n",
    "dfTest['emotions'] = y\n",
    "xtr, xts, ytr, yts = train_test_split(\n",
    "        dfTest[[i for i in range(0,52)]], dfTest['emotions'], test_size=0.8\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_iter': [50, 100, 200],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameter tuning for MPLClassifier\n",
    "\n",
    "penalty = ['l1', 'l2', 'elasticnet', 'none']\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "max_iter = [50, 100, 200]\n",
    "\n",
    "param = {'penalty': penalty, 'solver': solver, 'max_iter': max_iter}\n",
    "\n",
    "modeltest = LogisticRegression()\n",
    "\n",
    "modelgs = GridSearchCV(\n",
    "    modeltest,\n",
    "    param)\n",
    "modelgs.fit(xtr, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 50, 'penalty': 'l2', 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and extract features for each sound file\n",
    "def loadData(testSize=0.2):\n",
    "    x,y=[],[]\n",
    "    for file in neutral:\n",
    "            try:\n",
    "                emotion='neutral' # 01 for neutral emotion\n",
    "                feature=extractFeature(file)\n",
    "                x.append(feature)\n",
    "                y.append(emotion)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "    for file in angry:\n",
    "        try:\n",
    "            emotion='angry' # 01 for neutral emotion\n",
    "            feature=extractFeature(file)\n",
    "            x.append(feature)\n",
    "            y.append(emotion)\n",
    "        except:\n",
    "            continue\n",
    "    for file in happy:\n",
    "        try:\n",
    "            emotion='happy' # 01 for neutral emotion\n",
    "            feature=extractFeature(file)\n",
    "            x.append(feature)\n",
    "            y.append(emotion)\n",
    "        except:\n",
    "            continue\n",
    "    df = pd.DataFrame(x)\n",
    "    df['emotions'] = y\n",
    "    xtr, xts, ytr, yts = train_test_split(\n",
    "        df[[i for i in range(0,52)]], df['emotions'], test_size=testSize\n",
    "    )\n",
    "    return xtr, xts, ytr, yts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "xtr,xts,ytr,yts=loadData(testSize=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4439, 1110)\n"
     ]
    }
   ],
   "source": [
    "# Get the shape of the training and testing datasets\n",
    "print((xtr.shape[0], xts.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted: 52\n"
     ]
    }
   ],
   "source": [
    "# Get the number of features extracted\n",
    "print(f'Features extracted: {xtr.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making model\n",
    "model = LogisticRegression(max_iter= 50, penalty= 'l2', solver= 'lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=50,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for the test data\n",
    "yPred=model.predict(xts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.95%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy of model\n",
    "accuracy=accuracy_score(y_true=yts, y_pred=yPred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.68      0.69      0.68       394\n",
      "       happy       0.59      0.51      0.55       388\n",
      "     neutral       0.68      0.76      0.72       328\n",
      "\n",
      "    accuracy                           0.65      1110\n",
      "   macro avg       0.65      0.66      0.65      1110\n",
      "weighted avg       0.65      0.65      0.65      1110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yts, yPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
